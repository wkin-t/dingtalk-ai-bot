import asyncio
import random
import time
import base64
import dingtalk_stream
from dingtalk_stream import AckMessage
from app.config import DINGTALK_CLIENT_ID, DINGTALK_CLIENT_SECRET, MAX_HISTORY_LENGTH, DEFAULT_MODEL, CARD_TEMPLATE_ID, get_model_pricing, AVAILABLE_MODELS, AI_BACKEND
from app.memory import get_history, update_history, clear_history, get_session_key
from app.dingtalk_card import DingTalkCardHelper
from app.gemini_client import call_gemini_stream, analyze_complexity_with_model

# å°è¯•å¯¼å…¥ä½¿ç”¨ç»Ÿè®¡æ¨¡å—
try:
    from app.database import usage_stats, UsageStats
    USE_STATS = True
except Exception as e:
    USE_STATS = False
    print(f"âš ï¸ ä½¿ç”¨ç»Ÿè®¡æ¨¡å—ä¸å¯ç”¨: {e}")

# --- å…¨å±€å˜é‡å®šä¹‰ ---
message_buffer = {}
session_locks = {}  # ä¼šè¯çº§é”å­—å…¸
processing_sessions = set()  # æ­£åœ¨å¤„ç†çš„ä¼šè¯é›†åˆ

# å¤æ‚åº¦å…³é”®è¯
COMPLEX_KEYWORDS = [
    # ä»£ç ç›¸å…³
    "ä»£ç ", "ç¼–ç¨‹", "code", "python", "java", "javascript", "sql", "debug", "bug", "æŠ¥é”™", "error",
    "å‡½æ•°", "ç®—æ³•", "å®ç°", "å¼€å‘", "api", "æ¥å£",
    # æ•°å­¦/æ¨ç†
    "è®¡ç®—", "æ•°å­¦", "å…¬å¼", "è¯æ˜", "æ¨å¯¼", "åˆ†æ", "é€»è¾‘", "æ¨ç†",
    # æ·±åº¦åˆ†æ
    "è¯¦ç»†", "æ·±å…¥", "å…¨é¢", "æ¯”è¾ƒ", "å¯¹æ¯”", "ä¼˜ç¼ºç‚¹", "åŸç†", "æ¶æ„", "è®¾è®¡",
    "ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "æ€ä¹ˆ", "è§£é‡Š", "åˆ†æ",
    # åˆ›ä½œ
    "å†™ä¸€ç¯‡", "æ’°å†™", "åˆ›ä½œ", "æ–‡ç« ", "æŠ¥å‘Š", "æ–¹æ¡ˆ",
]

# Pro ä¸“ç”¨å…³é”®è¯ (éœ€è¦æ›´å¼ºæ¨ç†èƒ½åŠ›)
PRO_KEYWORDS = [
    # é«˜çº§æ¨ç†
    "è¯æ˜", "æ¨å¯¼", "è®ºè¯", "æ¨ç†è¿‡ç¨‹", "é€»è¾‘é“¾",
    # å¤æ‚æ¶æ„
    "ç³»ç»Ÿè®¾è®¡", "æ¶æ„è®¾è®¡", "æŠ€æœ¯æ–¹æ¡ˆ", "è®¾è®¡æ¨¡å¼",
    # æ·±åº¦åˆ†æ
    "æ·±åº¦åˆ†æ", "å…¨é¢åˆ†æ", "è¯¦ç»†åˆ†æ", "æ ¹æœ¬åŸå› ",
    # å¤æ‚æ•°å­¦
    "å¾®ç§¯åˆ†", "çº¿æ€§ä»£æ•°", "æ¦‚ç‡è®º", "ç»Ÿè®¡", "ä¼˜åŒ–",
    # ä¸“ä¸šé¢†åŸŸ
    "è®ºæ–‡", "ç ”ç©¶", "å­¦æœ¯", "ä¸“ä¸š",
    # ç”¨æˆ·æ˜ç¡®è¦æ±‚
    "ç”¨pro", "ä½¿ç”¨pro", "proæ¨¡å‹", "æ·±åº¦æ€è€ƒ",
]

SIMPLE_KEYWORDS = [
    "ä½ å¥½", "hi", "hello", "è°¢è°¢", "thanks", "å†è§", "bye",
    "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯", "å®šä¹‰", "ç®€å•",
]


def analyze_complexity(content: str, has_images: bool = False) -> dict:
    """
    åˆ†æé—®é¢˜å¤æ‚åº¦ï¼Œè¿”å›æ¨èçš„æ¨¡å‹å’Œ thinking level

    è·¯ç”±ç­–ç•¥:
    - Flash + minimal: ç®€å•é—®å€™
    - Flash + low: æ™®é€šé—®é¢˜
    - Flash + medium: ä¸­ç­‰å¤æ‚åº¦
    - Flash + high: å¤æ‚é—®é¢˜
    - Pro + high: è¶…å¤æ‚é—®é¢˜ (éœ€è¦æ·±åº¦æ¨ç†)

    Returns:
        {
            "model": "gemini-3-flash" or "gemini-3-pro-preview",
            "thinking_level": "minimal" | "low" | "medium" | "high",
            "reason": "åˆ†æåŸå› "
        }
    """
    content_lower = content.lower()
    content_len = len(content)

    # é»˜è®¤å€¼
    model = "gemini-3-flash"
    thinking_level = "low"
    reason = "æ™®é€šé—®é¢˜"

    # 1. æ£€æŸ¥æ˜¯å¦æ˜¯ç®€å•é—®å€™/é—²èŠ
    if content_len < 20:
        for kw in SIMPLE_KEYWORDS:
            if kw in content_lower:
                return {
                    "model": "gemini-3-flash",
                    "thinking_level": "minimal",
                    "reason": "ç®€å•é—®å€™"
                }

    # 2. ç»Ÿè®¡å…³é”®è¯åŒ¹é…
    complex_count = sum(1 for kw in COMPLEX_KEYWORDS if kw in content_lower)
    pro_count = sum(1 for kw in PRO_KEYWORDS if kw in content_lower)

    # 3. æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç å—
    has_code = "```" in content or content.count("\n") > 5

    # 4. å†³å®šæ¨¡å‹å’Œ thinking level

    # è¶…å¤æ‚é—®é¢˜ â†’ Pro + high
    if pro_count >= 2 or (pro_count >= 1 and complex_count >= 3):
        model = "gemini-3-pro-preview"
        thinking_level = "high"
        reason = f"æ·±åº¦æ¨ç† (Proå…³é”®è¯={pro_count}, å¤æ‚={complex_count})"

    # å¤æ‚é—®é¢˜ + é•¿æ–‡æœ¬ â†’ Pro + high
    elif complex_count >= 4 and content_len > 300:
        model = "gemini-3-pro-preview"
        thinking_level = "high"
        reason = f"å¤æ‚é•¿æ–‡ (å…³é”®è¯={complex_count}, é•¿åº¦={content_len})"

    # å¤æ‚ä»£ç é—®é¢˜ â†’ Flash + high (Flash ä»£ç èƒ½åŠ›ä¹Ÿå¾ˆå¼º)
    elif has_code and complex_count >= 2:
        model = "gemini-3-flash"
        thinking_level = "high"
        reason = f"ä»£ç é—®é¢˜ (å…³é”®è¯={complex_count})"

    # å¤æ‚é—®é¢˜ â†’ Flash + high
    elif complex_count >= 3:
        model = "gemini-3-flash"
        thinking_level = "high"
        reason = f"å¤æ‚é—®é¢˜ (å…³é”®è¯={complex_count})"

    # ä¸­ç­‰å¤æ‚ â†’ Flash + medium
    elif complex_count >= 1 or has_code:
        model = "gemini-3-flash"
        thinking_level = "medium"
        reason = f"ä¸­ç­‰å¤æ‚ (å…³é”®è¯={complex_count})"

    # é•¿æ–‡æœ¬ â†’ æå‡ thinking level
    if content_len > 500:
        if thinking_level == "low":
            thinking_level = "medium"
        elif thinking_level == "medium" and model == "gemini-3-flash":
            thinking_level = "high"
        reason += f" + é•¿æ–‡æœ¬({content_len}å­—)"

    # å›¾ç‰‡åˆ†æ â†’ è‡³å°‘ medium
    if has_images:
        if thinking_level in ["minimal", "low"]:
            thinking_level = "medium"
        reason += " + å›¾ç‰‡"

    return {
        "model": model,
        "thinking_level": thinking_level,
        "reason": reason
    }

class GeminiBotHandler(dingtalk_stream.ChatbotHandler):
    def __init__(self):
        super(GeminiBotHandler, self).__init__()
        self.card_helper = DingTalkCardHelper(DINGTALK_CLIENT_ID, DINGTALK_CLIENT_SECRET)
        self.card_template_id = CARD_TEMPLATE_ID  # ä»ç¯å¢ƒå˜é‡è¯»å–
        
        self.thinking_phrases = [
            "CPU æ­£åœ¨ç‡ƒçƒ§ ğŸ”¥", "æ­£åœ¨ç¿»é˜…ç™¾ç§‘å…¨ä¹¦ ğŸ“–", "è®©æˆ‘æƒ³æƒ³... ğŸ¤”",
            "æ­£åœ¨è¿æ¥å®‡å®™æ„è¯† ğŸŒŒ", "å¤´éƒ½è¦ç‚¸äº† ğŸ¤¯", "æ­£åœ¨ç–¯ç‹‚ç å­—ä¸­ âœï¸",
            "æ­£åœ¨è°ƒå–é‡å­ç®—åŠ› âš›ï¸", "å¤§è„‘é£é€Ÿè¿è½¬ä¸­ ğŸ§ ", "æ­£åœ¨å’Œæ•°æ®æ‰“æ¶ âš”ï¸",
            "ç¨ç­‰ï¼Œçµæ„Ÿé©¬ä¸Šå°±æ¥ ğŸ’¡"
        ]

    def _calculate_cost(self, model_usage: list) -> float:
        """æ ¹æ®æ¨¡å‹ç”¨é‡è®¡ç®—è´¹ç”¨ (ç¾å…ƒ)"""
        total_cost = 0.0
        for usage in model_usage:
            model = usage.get('model', 'default')
            input_tokens = usage.get('input_tokens', 0)
            output_tokens = usage.get('output_tokens', 0)
            pricing = get_model_pricing(model)
            # ä»·æ ¼æ˜¯æ¯ç™¾ä¸‡ token
            input_cost = (input_tokens / 1_000_000) * pricing['input']
            output_cost = (output_tokens / 1_000_000) * pricing['output']
            total_cost += input_cost + output_cost
        return total_cost

    async def _show_stats(self, incoming_message, session_key: str, user_id: str):
        """æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡"""
        try:
            # è·å–ç”¨æˆ·ç»Ÿè®¡
            user_stats = UsageStats.get_user_stats(user_id, days=7)
            # è·å–ç¾¤/ä¼šè¯ç»Ÿè®¡
            session_stats = UsageStats.get_session_stats(session_key, days=7)
            # è·å–å…¨å±€ç»Ÿè®¡
            global_stats = UsageStats.get_global_stats(days=7)

            # æ ¼å¼åŒ–ç»Ÿè®¡ä¿¡æ¯
            lines = ["## ğŸ“Š ä½¿ç”¨ç»Ÿè®¡ (è¿‘7å¤©)\n"]

            # ç”¨æˆ·ç»Ÿè®¡
            lines.append("### ğŸ‘¤ ä½ çš„ä½¿ç”¨æƒ…å†µ")
            if user_stats and user_stats.get('total_requests', 0) > 0:
                lines.append(f"- è¯·æ±‚æ¬¡æ•°: **{user_stats.get('total_requests', 0)}** æ¬¡")
                lines.append(f"- è¾“å…¥ Token: **{user_stats.get('total_input_tokens', 0):,}**")
                lines.append(f"- è¾“å‡º Token: **{user_stats.get('total_output_tokens', 0):,}**")
                lines.append(f"- å¹³å‡å»¶è¿Ÿ: **{int(user_stats.get('avg_latency_ms', 0)):,}** ms")
                # è®¡ç®—ç”¨æˆ·è´¹ç”¨
                model_usage = user_stats.get('model_usage', [])
                if model_usage:
                    user_cost = self._calculate_cost(model_usage)
                    lines.append(f"- ğŸ’° é¢„ä¼°è´¹ç”¨: **${user_cost:.4f}** (çº¦ Â¥{user_cost * 7.2:.2f})")
            else:
                lines.append("- æš‚æ— ä½¿ç”¨è®°å½•")

            # ç¾¤/ä¼šè¯ç»Ÿè®¡
            lines.append("\n### ğŸ’¬ æœ¬ç¾¤ä½¿ç”¨æƒ…å†µ")
            if session_stats and session_stats.get('total_requests', 0) > 0:
                lines.append(f"- è¯·æ±‚æ¬¡æ•°: **{session_stats.get('total_requests', 0)}** æ¬¡")
                lines.append(f"- å‚ä¸ç”¨æˆ·: **{session_stats.get('unique_users', 0)}** äºº")
                total_tokens = session_stats.get('total_input_tokens', 0) + session_stats.get('total_output_tokens', 0)
                lines.append(f"- æ€» Token: **{total_tokens:,}**")
            else:
                lines.append("- æš‚æ— ä½¿ç”¨è®°å½•")

            # å…¨å±€ç»Ÿè®¡
            lines.append("\n### ğŸŒ å…¨å±€ç»Ÿè®¡")
            if global_stats and global_stats.get('total_requests', 0) > 0:
                lines.append(f"- æ€»è¯·æ±‚: **{global_stats.get('total_requests', 0)}** æ¬¡")
                lines.append(f"- æ´»è·ƒç”¨æˆ·: **{global_stats.get('unique_users', 0)}** äºº")
                lines.append(f"- æ´»è·ƒç¾¤èŠ: **{global_stats.get('unique_sessions', 0)}** ä¸ª")
                total_tokens = global_stats.get('total_input_tokens', 0) + global_stats.get('total_output_tokens', 0)
                lines.append(f"- æ€» Token: **{total_tokens:,}**")

                # æ¨¡å‹åˆ†å¸ƒå’Œè´¹ç”¨
                model_dist = global_stats.get('model_distribution', [])
                if model_dist:
                    lines.append("\n**æ¨¡å‹åˆ†å¸ƒåŠè´¹ç”¨:**")
                    total_cost = 0.0
                    for m in model_dist[:5]:
                        model_name = m.get('model', 'unknown')
                        count = m.get('count', 0)
                        input_t = m.get('input_tokens', 0)
                        output_t = m.get('output_tokens', 0)
                        pricing = get_model_pricing(model_name)
                        cost = (input_t / 1_000_000) * pricing['input'] + (output_t / 1_000_000) * pricing['output']
                        total_cost += cost
                        # ç®€åŒ–æ¨¡å‹åæ˜¾ç¤º
                        model_short = model_name.replace("gemini-", "").replace("-preview", "")
                        lines.append(f"- {model_short}: {count}æ¬¡, ${cost:.4f}")

                    lines.append(f"\nğŸ’° **æ€»è´¹ç”¨: ${total_cost:.4f}** (çº¦ Â¥{total_cost * 7.2:.2f})")
            else:
                lines.append("- æš‚æ— ä½¿ç”¨è®°å½•")

            lines.append(f"\n---\n<font color='gray' size='1'>å®šä»·å‚è€ƒ: ai.google.dev/pricing | æ±‡ç‡: 1 USD = 7.2 CNY</font>")

            self.reply_markdown("ä½¿ç”¨ç»Ÿè®¡", "\n".join(lines), incoming_message)

        except Exception as e:
            print(f"âš ï¸ è·å–ç»Ÿè®¡å¤±è´¥: {e}")
            self.reply_markdown("ç³»ç»Ÿæç¤º", f"âš ï¸ è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}", incoming_message)

    def _build_display_content(self, thinking: str, response: str, is_thinking: bool = False) -> str:
        """
        æ„å»ºæ˜¾ç¤ºå†…å®¹ï¼ŒåŒ…å« thinking å’Œæ­£å¼å›å¤

        Args:
            thinking: æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹
            response: æ¨¡å‹çš„æ­£å¼å›å¤
            is_thinking: æ˜¯å¦æ­£åœ¨æ€è€ƒä¸­

        Returns:
            æ ¼å¼åŒ–çš„æ˜¾ç¤ºå†…å®¹
        """
        parts = []

        # æ˜¾ç¤º thinking å†…å®¹ (æŠ˜å æ ·å¼)
        if thinking:
            # æˆªå– thinking å†…å®¹ï¼Œé¿å…è¿‡é•¿
            thinking_display = thinking
            if len(thinking) > 2000:
                thinking_display = thinking[:2000] + "..."

            if is_thinking:
                parts.append(f"<details open>\n<summary>ğŸ§  **æ­£åœ¨æ€è€ƒä¸­...**</summary>\n\n{thinking_display}\n</details>")
            else:
                parts.append(f"<details>\n<summary>ğŸ§  **æ€è€ƒè¿‡ç¨‹** (ç‚¹å‡»å±•å¼€)</summary>\n\n{thinking_display}\n</details>")

        # æ˜¾ç¤ºæ­£å¼å›å¤
        if response:
            # è¿‡æ»¤æ‘˜è¦
            display_response = response.replace("[AILoading]", "â€¦â€¦")
            lines = display_response.split('\n')
            filtered_lines = [line for line in lines if not line.strip().startswith("> ğŸ“ æ¦‚è¦ï¼š")]
            display_response = "\n".join(filtered_lines).strip()

            if thinking:
                parts.append("\n---\n")
            parts.append(display_response)
        elif is_thinking:
            parts.append("\n\nâ³ *ç­‰å¾…å›å¤ç”Ÿæˆ...*")

        return "".join(parts)

    async def _update_card_throttled(self, out_track_id: str, content: str, last_update_time: float, is_first: bool) -> float:
        """èŠ‚æµæ›´æ–°å¡ç‰‡ - å¢åŠ èŠ‚æµé—´éš”ä»¥å‡å°‘ API å‹åŠ›"""
        import time
        current_time = time.time()

        # å¢åŠ èŠ‚æµé—´éš”ï¼šç¬¬ä¸€æ¬¡ç«‹å³æ›´æ–°ï¼Œåç»­è‡³å°‘é—´éš” 1 ç§’
        if is_first or current_time - last_update_time > 1.0:
            await self.card_helper.stream_update(out_track_id, content, is_finalize=False, content_key="msgContent")
            return current_time

        return last_update_time

    async def handle_gemini_stream(self, incoming_message, content, conversation_id, at_user_ids, image_data_list=None, group_info=None):
        print(f"ğŸš€ å¼€å§‹å¤„ç† Gemini è¯·æ±‚: {content} (User: {incoming_message.sender_id})")
        if image_data_list:
            print(f"ğŸ–¼ï¸ æ”¶åˆ°å›¾ç‰‡æ•°é‡: {len(image_data_list)}")
        
        session_key = get_session_key(conversation_id, incoming_message.sender_id)
        
        # è·å–å®Œæ•´å†å²è®°å½•
        full_history = get_history(session_key)
        
        # æˆªå–æœ€è¿‘çš„ N æ¡å‘é€ç»™ Gemini
        if len(full_history) > MAX_HISTORY_LENGTH:
            history_messages = full_history[-MAX_HISTORY_LENGTH:]
        else:
            history_messages = full_history
            
        # æ„é€  System Prompt
        from datetime import datetime, timezone, timedelta
        # è·å–åŒ—äº¬æ—¶é—´ (UTC+8)
        beijing_tz = timezone(timedelta(hours=8))
        current_time = datetime.now(beijing_tz).strftime("%Y-%m-%d %H:%M:%S")

        # æå–æ—¥æœŸä¿¡æ¯
        current_date = datetime.now(beijing_tz)
        year = current_date.year
        month = current_date.month
        day = current_date.day

        system_prompt = f"""ä½ æ˜¯ Gemï¼Œä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚ä½ çš„å›ç­”åº”è¯¥å‡†ç¡®ï¼Œä¸è¦äº§ç”Ÿå¹»è§‰ã€‚

â° é‡è¦æ—¶é—´ä¿¡æ¯ï¼ˆè¯·åŠ¡å¿…è®°ä½ï¼‰:
- ä»Šå¤©æ˜¯: {year} å¹´ {month} æœˆ {day} æ—¥
- å½“å‰å®Œæ•´æ—¶é—´: {current_time} (åŒ—äº¬æ—¶é—´, UTC+8)
- ä½ çš„è®­ç»ƒæ•°æ®å¯èƒ½æˆªæ­¢äº 2025 å¹´ï¼Œä½†ç°åœ¨å·²ç»æ˜¯ {year} å¹´äº†
- å½“å›ç­”æ¶‰åŠ"ä»Šå¹´"ã€"ç°åœ¨"ã€"å½“å‰"ç­‰æ—¶é—´ç›¸å…³é—®é¢˜æ—¶ï¼Œè¯·ä½¿ç”¨ä¸Šè¿°æ—¥æœŸè€Œéè®­ç»ƒæ•°æ®ä¸­çš„æ—¶é—´

æ ¼å¼è§„åˆ™:
1. ä¸è¦ä½¿ç”¨ LaTeX è¯­æ³•ï¼ˆå¦‚ $x^2$ æˆ– $$...$$ï¼‰ã€‚ç”¨çº¯æ–‡æœ¬æˆ– Unicode è¡¨ç¤ºæ•°å­¦å…¬å¼ï¼ˆå¦‚ x^2, sqrt(x)ï¼‰ã€‚
2. å¯ä»¥ä½¿ç”¨ Markdownï¼šè¡¨æ ¼ã€åŠ ç²—ã€æ–œä½“ã€åˆ—è¡¨ã€ä»£ç å—ã€‚

ä¸Šä¸‹æ–‡æ„ŸçŸ¥:
- å¯¹è¯å†å²ä¸­åŒ…å«ç”¨æˆ·æ˜µç§°å’Œæ—¶é—´æˆ³ï¼Œæ ¼å¼ä¸º '[æ—¶é—´] æ˜µç§°: æ¶ˆæ¯'ã€‚
- å¼•ç”¨ç”¨æˆ·å‘è¨€æ—¶ï¼Œå¯ä»¥æåŠå…¶æ˜µç§°å’Œæ—¶é—´ï¼ˆå¦‚ 'æ­£å¦‚å¼ ä¸‰åœ¨ 14:30 æ‰€è¯´...'ï¼‰ã€‚
- æ‰€æœ‰æ—¶é—´å‡ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8)ã€‚

é‡ç‚¹:
- ç›´æ¥å›åº”æœ€æ–°ç”¨æˆ·çš„è¾“å…¥ã€‚
- ä»…å°†ä¹‹å‰çš„ä¸Šä¸‹æ–‡ä½œä¸ºå‚è€ƒã€‚

è¾“å‡ºè¦æ±‚:
- ç›´æ¥è¾“å‡ºç­”æ¡ˆã€‚ä¸è¦è¾“å‡ºçŠ¶æ€æŒ‡ç¤ºå™¨æˆ– '[AILoading]'ã€‚
- ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚æŠ€æœ¯æœ¯è¯­å¯åœ¨ä¸­æ–‡ååŠ è‹±æ–‡æ‹¬å·ï¼ˆå¦‚ï¼šæœºå™¨å­¦ä¹  (Machine Learning)ï¼‰ã€‚

æœç´¢å’Œå®æ—¶ä¿¡æ¯:
- å¦‚æœå¯ç”¨äº† Google Searchï¼Œæœç´¢ç»“æœä¼šè‡ªåŠ¨æä¾›ç»™ä½ 
- å½“æœç´¢ç»“æœä¸ä½ çš„è®­ç»ƒæ•°æ®å†²çªæ—¶ï¼Œä¼˜å…ˆç›¸ä¿¡æœç´¢ç»“æœ
- ç‰¹åˆ«æ˜¯æ¶‰åŠæ—¶é—´ã€æ—¥æœŸã€æœ€æ–°äº‹ä»¶æ—¶ï¼Œæœç´¢ç»“æœæ¯”è®­ç»ƒæ•°æ®æ›´å‡†ç¡®
- å¦‚æœç”¨æˆ·è´¨ç–‘ä½ å¯¹æ—¶é—´çš„è®¤çŸ¥ï¼Œè¯·å†æ¬¡ç¡®è®¤ï¼šä»Šå¤©æ˜¯ {year} å¹´ {month} æœˆ {day} æ—¥

æ€è€ƒè¯­è¨€:
- è¯·ä½¿ç”¨ä¸­æ–‡è¿›è¡Œæ€è€ƒå’Œæ¨ç†ã€‚ä½ çš„å†…éƒ¨æ€è€ƒè¿‡ç¨‹ä¹Ÿåº”è¯¥ç”¨ä¸­æ–‡è¡¨è¾¾ã€‚"""

        # æ³¨å…¥ç¾¤ä¿¡æ¯ (åªæ³¨å…¥ç¾¤å)
        if group_info:
            group_name = group_info.get('name', 'Unknown Group')
            
            group_context = f"\n\nGROUP CONTEXT:\nYou are currently in a DingTalk group chat named '{group_name}'.\n\nTASK:\nBased on the group name, briefly analyze what technical capabilities or domain knowledge you might need to assist this group effectively. Keep this analysis internal to guide your responses."
            system_prompt += group_context

        messages = []
        messages.append({
            "role": "system",
            "content": system_prompt
        })

        # æ ¼å¼åŒ–å†å²æ¶ˆæ¯ï¼Œæ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
        formatted_history = []
        for msg in history_messages:
            formatted_msg = {"role": msg["role"]}
            content = msg.get("content", "")
            timestamp = msg.get("timestamp")

            # å¦‚æœæœ‰æ—¶é—´æˆ³ï¼Œæ·»åŠ åˆ°å†…å®¹å‰é¢
            if timestamp and msg["role"] == "user":
                # ç”¨æˆ·æ¶ˆæ¯æ ¼å¼: [æ—¶é—´] åŸå§‹å†…å®¹
                formatted_msg["content"] = f"[{timestamp}] {content}"
            else:
                # AI å›å¤ä¸æ·»åŠ æ—¶é—´æˆ³å‰ç¼€ï¼ˆä¿æŒç®€æ´ï¼‰
                formatted_msg["content"] = content

            formatted_history.append(formatted_msg)

        if image_data_list:
            if history_messages and history_messages[-1]['role'] == 'user':
                pass

            from datetime import datetime, timezone, timedelta
            beijing_tz = timezone(timedelta(hours=8))
            current_timestamp = datetime.now(beijing_tz).strftime("%Y-%m-%d %H:%M:%S")

            sender_nick = incoming_message.sender_nick or "User"

            user_message_content = []
            user_message_content.append({"type": "text", "text": f"[{current_timestamp}] {sender_nick}: [å›¾ç‰‡x{len(image_data_list)}] {content}"})
            
            for i, img_data in enumerate(image_data_list):
                b64_image = base64.b64encode(img_data).decode('utf-8')
                print(f"ğŸ–¼ï¸ å¤„ç†ç¬¬ {i+1} å¼ å›¾ç‰‡ï¼Œå¤§å°: {len(img_data)} bytes")
                user_message_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{b64_image}"}
                })

            messages.extend(formatted_history)
            messages.append({"role": "user", "content": user_message_content})

        else:
            # æ— å›¾ç‰‡æ—¶ï¼šå…ˆæ·»åŠ å†å²è®°å½•ï¼Œå†æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            from datetime import datetime, timezone, timedelta
            beijing_tz = timezone(timedelta(hours=8))
            current_timestamp = datetime.now(beijing_tz).strftime("%Y-%m-%d %H:%M:%S")

            sender_nick = incoming_message.sender_nick or "User"
            text_content = f"[{current_timestamp}] {sender_nick}: {content}"
            messages.extend(formatted_history)
            messages.append({"role": "user", "content": text_content})

        # åˆå§‹åŒ– AI å¡ç‰‡
        thinking_text = random.choice(self.thinking_phrases)
        
        card_data = {
            "msgTitle": "Gemini AI",
            "thinkingText": thinking_text,
            "msgContent": "Thinking...", 
            "isError": "false",
            "flowStatus": "1",
            "config": {"autoLayout": True} 
        }
        
        out_track_id = await self.card_helper.create_and_deliver(
            conversation_id, 
            self.card_template_id,
            card_data,
            at_user_ids
        )
        
        if not out_track_id:
            self.reply_markdown("ç³»ç»Ÿé”™è¯¯", "âš ï¸ æ— æ³•åˆ›å»º AI å¡ç‰‡ï¼Œè¯·æ£€æŸ¥æƒé™æˆ–æ¨¡æ¿ IDã€‚", incoming_message)
            return

        print(f"âœ… å¡ç‰‡åˆ›å»ºæˆåŠŸï¼ŒID: {out_track_id}")

        # æ™ºèƒ½è·¯ç”±ï¼šæ ¹æ® AI_BACKEND é€‰æ‹©åç«¯
        print(f"ğŸ”„ [è·¯ç”±] AI åç«¯: {AI_BACKEND}")
        has_images = bool(image_data_list)

        if AI_BACKEND == "openclaw":
            # OpenClaw æ¨¡å¼: å†…éƒ¨å¤„ç†æ¨¡å‹é€‰æ‹©
            target_model = "openclaw"
            thinking_level = "auto"
            need_search = False
            print(f"ğŸ¯ OpenClaw æ¨¡å¼: ç”± Gateway è‡ªåŠ¨å¤„ç†è·¯ç”±")
        else:
            # Gemini æ¨¡å¼: æ™ºèƒ½è·¯ç”±åˆ†æ
            print(f"ğŸ”„ [è·¯ç”±] å¼€å§‹æ™ºèƒ½è·¯ç”±åˆ†æ...")
            try:
                complexity = await analyze_complexity_with_model(content, has_images)
                print(f"ğŸ”„ [è·¯ç”±] é¢„åˆ†æè¿”å›: {complexity}")
            except Exception as e:
                print(f"âŒ [è·¯ç”±] é¢„åˆ†æå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                complexity = {
                    "model": "gemini-3-flash-preview",
                    "thinking_level": "low",
                    "need_search": False,
                    "reason": "è·¯ç”±å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤"
                }
            target_model = complexity.get("model", "gemini-3-flash-preview")
            thinking_level = complexity.get("thinking_level", "low")
            need_search = complexity.get("need_search", False)
            print(f"ğŸ¯ æ™ºèƒ½è·¯ç”±: {complexity.get('reason', 'é»˜è®¤')} â†’ æ¨¡å‹={target_model}, thinking={thinking_level}, search={need_search}")

        full_response = ""
        full_thinking = ""  # çœŸå®çš„ thinking å†…å®¹
        last_update_time = time.time()
        is_first_chunk = True
        is_thinking = False  # æ˜¯å¦æ­£åœ¨è¾“å‡º thinking
        usage_info = None  # ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯

        sender_name = incoming_message.sender_nick or "User"
        at_header = f"ğŸ‘‹ @{sender_name} \n\n"

        try:
            # æ ¹æ®åç«¯é€‰æ‹©è°ƒç”¨ä¸åŒçš„ API
            if AI_BACKEND == "openclaw":
                from app.openclaw_client import call_openclaw_stream
                stream = call_openclaw_stream(
                    messages,
                    conversation_id=conversation_id,
                    sender_id=incoming_message.sender_id,
                    sender_nick=sender_name
                )
            else:
                stream = call_gemini_stream(
                    messages,
                    target_model=target_model,
                    thinking_level=thinking_level,
                    enable_search=need_search
                )

            async for chunk in stream:
                # å¤„ç†ä½¿ç”¨ç»Ÿè®¡
                if "usage" in chunk:
                    usage_info = chunk["usage"]
                    continue

                if "error" in chunk:
                    print(f"âŒ {chunk['error']}")
                    await self.card_helper.stream_update(out_track_id, f"âŒ **API è¯·æ±‚å¤±è´¥**\n\n{chunk['error']}", is_finalize=True, content_key="msgContent")
                    return

                # å¤„ç† thinking å¼€å§‹/ç»“æŸæ ‡è®°
                if chunk.get("thinking_start"):
                    is_thinking = True
                    continue
                if chunk.get("thinking_end"):
                    is_thinking = False
                    continue

                # å¤„ç† thinking å†…å®¹
                thinking_delta = chunk.get("thinking", "")
                if thinking_delta:
                    full_thinking += thinking_delta
                    # æ„é€ æ˜¾ç¤ºå†…å®¹ï¼šthinking + æ­£å¼å›å¤
                    display_content = self._build_display_content(full_thinking, full_response, is_thinking=True)
                    await self._update_card_throttled(out_track_id, display_content, last_update_time, is_first_chunk)
                    if is_first_chunk:
                        is_first_chunk = False
                        last_update_time = time.time()
                    continue

                # å¤„ç†æ­£å¼å›å¤å†…å®¹
                content_delta = chunk.get("content", "")
                if content_delta:
                    content_delta = content_delta.replace("[AILoading]", "")
                    full_response += content_delta

                    # æ„é€ æ˜¾ç¤ºå†…å®¹
                    display_content = self._build_display_content(full_thinking, full_response, is_thinking=False)

                    if is_first_chunk:
                        is_first_chunk = False
                        await self.card_helper.stream_update(out_track_id, display_content, is_finalize=False, content_key="msgContent")
                        last_update_time = time.time()
                        continue

                    current_time = time.time()
                    # å¢åŠ èŠ‚æµé—´éš”åˆ° 1 ç§’ï¼Œå‡å°‘ API è¯·æ±‚é¢‘ç‡
                    if current_time - last_update_time > 1.0:
                        await self.card_helper.stream_update(out_track_id, display_content, is_finalize=False, content_key="msgContent")
                        last_update_time = current_time

            print(f"âœ… æµå¼å“åº”ç»“æŸï¼Œæ€»é•¿åº¦: {len(full_response)}, thinking: {len(full_thinking)}")

            # è®°å½•ä½¿ç”¨ç»Ÿè®¡
            if USE_STATS and usage_info:
                try:
                    usage_stats.record(
                        session_key=session_key,
                        user_id=incoming_message.sender_id,
                        model=usage_info.get("model", DEFAULT_MODEL),
                        input_tokens=usage_info.get("input_tokens", 0),
                        output_tokens=usage_info.get("output_tokens", 0),
                        latency_ms=usage_info.get("latency_ms", 0)
                    )
                    print(f"ğŸ“Š å·²è®°å½•ä½¿ç”¨ç»Ÿè®¡: {usage_info}")
                except Exception as e:
                    print(f"âš ï¸ è®°å½•ç»Ÿè®¡å¤±è´¥: {e}")

            full_response = full_response.replace("[AILoading]", "")
            clean_response = full_response.strip()

            # æ„å»ºçŠ¶æ€æ ï¼šåªæœ‰ thinking æ—¶æ‰æ˜¾ç¤ºæ‘˜è¦ï¼Œé¿å…é‡å¤æ˜¾ç¤ºå†…å®¹
            status_text = ""
            if full_thinking:
                # æˆªå– thinking å‰ 80 ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
                thinking_brief = full_thinking[:80].replace("\n", " ").strip()
                if len(full_thinking) > 80:
                    thinking_brief += "..."
                status_text = f"<font color='#aaaaaa' size='2'>ğŸ§  {thinking_brief}</font>"
            # æ²¡æœ‰ thinking æ—¶ä¸æ˜¾ç¤ºæ‘˜è¦ï¼Œé¿å…ä¸ä¸»å†…å®¹é‡å¤

            # æ˜¾ç¤ºæ¨¡å‹ã€thinking level å’Œè”ç½‘çŠ¶æ€
            model_short = target_model.replace("gemini-", "").replace("-preview", "")
            search_icon = "ğŸŒ" if need_search else ""
            status_text += f"\n\n<font color='#808080' size='2'>ğŸ¤– {model_short} | ğŸ§  {thinking_level} {search_icon}</font>"

            buttons = [
                {
                    "text": "ğŸ§¹ æ¸…ç©º",
                    "color": "grey", 
                    "event": {
                        "type": "openUrl",
                        "params": {"url": "dtmd://dingtalkclient/sendMessage?content=ğŸ§¹ æ¸…ç©ºè®°å¿†"}
                    }
                },
                {
                    "text": "ğŸ”„ é‡è¯•",
                    "color": "blue", 
                    "event": {
                        "type": "openUrl",
                        "params": {"url": "dtmd://dingtalkclient/sendMessage?content=" + (content or "é‡è¯•")}
                    }
                },
                {
                    "text": "ğŸ“ æ€»ç»“",
                    "color": "grey",
                    "event": {
                        "type": "openUrl",
                        "params": {"url": "dtmd://dingtalkclient/sendMessage?content=ğŸ“ æ€»ç»“æ‘˜è¦"}
                    }
                },
                {
                    "text": "ğŸ‡¬ğŸ‡§ ç¿»è¯‘",
                    "color": "grey",
                    "event": {
                        "type": "openUrl",
                        "params": {"url": "dtmd://dingtalkclient/sendMessage?content=ğŸ‡¬ğŸ‡§ ç¿»è¯‘æˆè‹±æ–‡"}
                    }
                }
            ]
            
            final_content = at_header + clean_response
            
            # è®°å½•å†å² (ä½¿ç”¨ update_history å†™å…¥æ–‡ä»¶)
            update_history(session_key, user_msg=None, assistant_msg=full_response)
            
            await self.card_helper.stream_update(
                out_track_id,
                final_content,
                is_finalize=True,
                content_key="msgContent"
            )
            
            update_data = {
                "msgContent": final_content, 
                "statusText": status_text,
                "msgButtons": buttons,
                "flowStatus": "3" 
            }
            print(f"ğŸ”„ æ­£åœ¨å…¨é‡æ›´æ–°å¡ç‰‡: {update_data.keys()}")
            
            success = await self.card_helper.update_card(out_track_id, update_data)
            
            if not success:
                print("âš ï¸ å…¨é‡æ›´æ–°å¤±è´¥ï¼Œå¯ç”¨å…œåº•æ–¹æ¡ˆï¼šæ‹¼æ¥æŒ‰é’®åˆ°æ­£æ–‡")
                buttons_md = (
                    "\n\n"
                    "[ğŸ§¹ æ¸…ç©º](dtmd://dingtalkclient/sendMessage?content=ğŸ§¹ æ¸…ç©ºè®°å¿†) | "
                    "[ğŸ”„ é‡è¯•](dtmd://dingtalkclient/sendMessage?content=" + (content or "é‡è¯•") + ") | "
                    "[ğŸ“ æ€»ç»“](dtmd://dingtalkclient/sendMessage?content=ğŸ“ æ€»ç»“æ‘˜è¦) | "
                    "[ğŸ‡¬ğŸ‡§ ç¿»è¯‘](dtmd://dingtalkclient/sendMessage?content=ğŸ‡¬ğŸ‡§ ç¿»è¯‘æˆè‹±æ–‡)"
                )
                if status_text:
                    final_content += "\n\n---\n" + status_text
                final_content += buttons_md
                
                await self.card_helper.stream_update(
                    out_track_id,
                    final_content,
                    is_finalize=True,
                    content_key="msgContent"
                )
            
            print(f"âœ… [DingTalk Stream] AI å¡ç‰‡æµå¼å“åº”å®Œæˆ")

        except Exception as e:
            error_msg = f"ç³»ç»Ÿå¼‚å¸¸: {str(e)}"
            print(f"ğŸ’¥ {error_msg}")
            try:
                await self.card_helper.stream_update(
                    out_track_id,
                    f"ğŸ’¥ **ç³»ç»Ÿå¼‚å¸¸**\n\n{error_msg}",
                    is_finalize=True,
                    content_key="msgContent"
                )
            except:
                pass

    async def process_buffered_messages(self, session_key):
        await asyncio.sleep(2.0)

        if session_key not in message_buffer:
            return

        # è·å–æˆ–åˆ›å»ºä¼šè¯é”
        if session_key not in session_locks:
            session_locks[session_key] = asyncio.Lock()

        async with session_locks[session_key]:
            # å†æ¬¡æ£€æŸ¥ï¼Œé˜²æ­¢åœ¨ç­‰å¾…é”æœŸé—´è¢«å…¶ä»–ä»»åŠ¡å¤„ç†
            if session_key not in message_buffer:
                return

            # æ ‡è®°æ­£åœ¨å¤„ç†
            processing_sessions.add(session_key)

            try:
                data = message_buffer[session_key]
                del message_buffer[session_key]

                content_list = data["content"]
                image_list = data["images"]
                incoming_message = data["incoming_message"]
                at_user_ids = data["at_user_ids"]

                full_content = "\n".join(content_list)

                # å¦‚æœåªæœ‰å›¾ç‰‡æ²¡æœ‰æ–‡å­—ï¼Œä½¿ç”¨é»˜è®¤æç¤º
                if not full_content and image_list:
                    full_content = "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ ã€åœºæ™¯ã€æ–‡å­—ç­‰ä¿¡æ¯ã€‚"

                sender_nick = incoming_message.sender_nick or "User"
                history_content = full_content
                if image_list:
                    history_content += f" [å›¾ç‰‡x{len(image_list)}]"

                # è·å–ç¾¤ä¿¡æ¯ (åªè·å–ç¾¤å)
                group_info = None
                if incoming_message.conversation_type == '2':  # ç¾¤èŠ
                    group_name = ""

                    if hasattr(incoming_message, 'conversation_title') and incoming_message.conversation_title:
                        group_name = incoming_message.conversation_title
                    else:
                        info = await self.card_helper.get_group_info(incoming_message.conversation_id)
                        if info and hasattr(info, 'title'):
                            group_name = info.title

                    if group_name:
                        group_info = {'name': group_name}
                        print(f"âœ… è·å–åˆ°ç¾¤ä¿¡æ¯: {group_name}")

                update_history(session_key, history_content, assistant_msg=None, sender_nick=sender_nick)
                print(f"ğŸ“¥ [DingTalk Stream] å¤„ç†åˆå¹¶æ¶ˆæ¯: {history_content} (User: {sender_nick})")

                await self.handle_gemini_stream(incoming_message, full_content, incoming_message.conversation_id, at_user_ids, image_list, group_info)
            finally:
                # æ¸…é™¤æ­£åœ¨å¤„ç†æ ‡è®°
                processing_sessions.discard(session_key)

    async def process(self, callback: dingtalk_stream.CallbackMessage):
        try:
            incoming_message = dingtalk_stream.ChatbotMessage.from_dict(callback.data)
            
            msg_type = incoming_message.message_type
            content = ""
            image_data_list = [] 
            
            if msg_type == "text":
                content = incoming_message.text.content.strip()
            elif msg_type == "picture":
                download_code = incoming_message.image_content.download_code
                print(f"ğŸ“¥ æ”¶åˆ°å›¾ç‰‡æ¶ˆæ¯ï¼Œæ­£åœ¨ä¸‹è½½... Code: {download_code}")
                img_data = await self.card_helper.download_file(download_code)
                if img_data:
                    print(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(img_data)} bytes")
                    image_data_list.append(img_data)
                    content = "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ ã€åœºæ™¯ã€æ–‡å­—ç­‰ä¿¡æ¯ã€‚"
                else:
                    content = "[å›¾ç‰‡ä¸‹è½½å¤±è´¥]"
            elif msg_type == "richText":
                rich_list = incoming_message.rich_text_content.rich_text_list
                print(f"ğŸ“¥ æ”¶åˆ°å¯Œæ–‡æœ¬æ¶ˆæ¯ï¼ŒåŒ…å« {len(rich_list)} ä¸ªå…ƒç´ ") 
                for item in rich_list:
                    if "text" in item:
                        content += item["text"]
                    if "downloadCode" in item: 
                        download_code = item["downloadCode"]
                        print(f"ğŸ“¥ æ”¶åˆ°å¯Œæ–‡æœ¬å›¾ç‰‡ï¼Œæ­£åœ¨ä¸‹è½½... Code: {download_code}")
                        img_data = await self.card_helper.download_file(download_code)
                        if img_data:
                            print(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ")
                            image_data_list.append(img_data)
                        await asyncio.sleep(0.5)
            
            if not content and not image_data_list:
                return AckMessage.STATUS_OK, 'OK'

            sender_id = incoming_message.sender_staff_id or incoming_message.sender_id
            conversation_id = incoming_message.conversation_id 
            session_key = get_session_key(conversation_id, sender_id)

            should_reply = False
            if incoming_message.conversation_type == '1': 
                should_reply = True
            elif incoming_message.is_in_at_list: 
                should_reply = True
            
            if not should_reply:
                sender_nick = incoming_message.sender_nick or "User"
                update_history(session_key, content if content else "[å›¾ç‰‡]", assistant_msg=None, sender_nick=sender_nick)
                return AckMessage.STATUS_OK, 'OK'

            at_users = incoming_message.at_users or []
            at_user_ids = []
            for user in at_users:
                if hasattr(user, 'dingtalk_id'):
                    at_user_ids.append(user.dingtalk_id)
                elif hasattr(user, 'staff_id'):
                    at_user_ids.append(user.staff_id)
                elif isinstance(user, dict):
                    at_user_ids.append(user.get('dingtalkId'))
            if sender_id and sender_id not in at_user_ids:
                at_user_ids.append(sender_id)

            if content == "/clear" or content == "æ¸…ç©ºä¸Šä¸‹æ–‡" or content == "ğŸ§¹ æ¸…ç©ºè®°å¿†":
                clear_history(session_key)
                self.reply_markdown("ç³»ç»Ÿæç¤º", "ğŸ§¹ ä½ çš„ä¸Šä¸‹æ–‡å·²æ¸…ç©º", incoming_message)
                return AckMessage.STATUS_OK, 'OK'

            # æŸ¥çœ‹ç»Ÿè®¡å‘½ä»¤
            if content == "/stats" or content == "ğŸ“Š ç»Ÿè®¡":
                if USE_STATS:
                    await self._show_stats(incoming_message, session_key, sender_id)
                else:
                    self.reply_markdown("ç³»ç»Ÿæç¤º", "âš ï¸ ç»Ÿè®¡åŠŸèƒ½ä¸å¯ç”¨", incoming_message)
                return AckMessage.STATUS_OK, 'OK'

            # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†è¯¥ä¼šè¯ (é˜²æ­¢å¹¶å‘ç«æ€)
            # å¦‚æœæ­£åœ¨å¤„ç†ä¸”æ²¡æœ‰ç¼“å†²åŒºï¼Œåˆ›å»ºç¼“å†²åŒºè®©æ¶ˆæ¯æ’é˜Ÿ
            if session_key in processing_sessions and session_key not in message_buffer:
                print(f"â³ ä¼šè¯æ­£åœ¨å¤„ç†ä¸­ï¼Œå°†æ¶ˆæ¯åŠ å…¥ç¼“å†²åŒºæ’é˜Ÿ: {session_key}")
                message_buffer[session_key] = {
                    "content": [],
                    "images": [],
                    "incoming_message": incoming_message,
                    "at_user_ids": at_user_ids
                }

            if session_key in message_buffer:
                message_buffer[session_key]["timer"].cancel()
            else:
                message_buffer[session_key] = {
                    "content": [],
                    "images": [],
                    "incoming_message": incoming_message, 
                    "at_user_ids": at_user_ids
                }
            
            if content:
                message_buffer[session_key]["content"].append(content)
            if image_data_list:
                message_buffer[session_key]["images"].extend(image_data_list)
            
            message_buffer[session_key]["incoming_message"] = incoming_message
            
            task = asyncio.create_task(self.process_buffered_messages(session_key))
            message_buffer[session_key]["timer"] = task

        except Exception as e:
            print(f"ğŸ’¥ [DingTalk Stream] Process å¼‚å¸¸: {e}")

        return AckMessage.STATUS_OK, 'OK'