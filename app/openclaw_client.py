# -*- coding: utf-8 -*-
"""
OpenClaw Gateway HTTP å®¢æˆ·ç«¯
ä½¿ç”¨ OpenAI å…¼å®¹çš„ /v1/chat/completions ç«¯ç‚¹ (SSE æµå¼)

ç«¯ç‚¹: http://172.17.0.1:48789/v1/chat/completions (ç»è¿‡ Safeline WAF)
è®¤è¯: Authorization: Bearer <gateway token>
æ ¼å¼: æ ‡å‡† OpenAI SDK æ ¼å¼

æ”¯æŒå¤š Agent è·¯ç”±ï¼š
- æ ¹æ® conversation_id åŠ¨æ€é€‰æ‹© agent
- é…ç½®åœ¨ OPENCLAW_GROUP_AGENT_MAPPING ç¯å¢ƒå˜é‡ä¸­
"""
import asyncio
import json
import time
import base64
import uuid
from typing import List, Dict, AsyncGenerator, Optional
import aiohttp
import websockets
from app.config import (
    OPENCLAW_HTTP_URL,
    OPENCLAW_GATEWAY_TOKEN,
    OPENCLAW_GATEWAY_TRANSPORT,
    OPENCLAW_GATEWAY_WS_URL,
    get_agent_for_conversation,
)


PROTOCOL_VERSION = 3


def _derive_ws_url(http_url: str) -> str:
    """
    Best-effort derive a Gateway WS URL from the OpenAI-compatible HTTP endpoint.
    The gateway accepts WS upgrades on any path, but "/ws" is commonly used behind reverse proxies.
    """
    raw = (http_url or "").strip()
    if not raw:
        return ""
    # http(s) -> ws(s)
    if raw.startswith("https://"):
        base = "wss://" + raw[len("https://"):]
    elif raw.startswith("http://"):
        base = "ws://" + raw[len("http://"):]
    else:
        base = raw

    # Strip OpenAI-compatible path if present.
    base = base.replace("/v1/chat/completions", "")
    if base.endswith("/"):
        base = base[:-1]
    return base + "/ws"


async def _ws_wait_for_response(ws, req_id: str, timeout_s: float = 30.0) -> dict:
    """Wait until we receive a response frame with matching id."""
    deadline = time.time() + timeout_s
    while True:
        remaining = max(0.1, deadline - time.time())
        raw = await asyncio.wait_for(ws.recv(), timeout=remaining)
        obj = json.loads(raw)
        if obj.get("type") == "res" and obj.get("id") == req_id:
            return obj


async def _ws_wait_for_challenge(ws, timeout_s: float = 10.0) -> str:
    """Wait for connect.challenge and return nonce (if present)."""
    deadline = time.time() + timeout_s
    while True:
        remaining = max(0.1, deadline - time.time())
        raw = await asyncio.wait_for(ws.recv(), timeout=remaining)
        obj = json.loads(raw)
        if obj.get("type") == "event" and obj.get("event") == "connect.challenge":
            payload = obj.get("payload") or {}
            nonce = payload.get("nonce")
            return nonce if isinstance(nonce, str) else ""


async def call_openclaw_ws_chat_stream(
    *,
    message: str,
    conversation_id: str,
    sender_id: str,
    sender_nick: str = "User",
    image_data_list: Optional[List[bytes]] = None,
    timeout_s: float = 300.0,
) -> AsyncGenerator[Dict, None]:
    """
    Call OpenClaw Gateway WebSocket protocol via chat.send.

    This is closer to official channel plugins:
    - Gateway manages session memory/transcript by sessionKey
    - Supports image attachments (base64) via chat.send params.attachments

    Notes:
    - chat.send attachments currently only accept images (audio/file should use tools-invoke first).
    - We embed the agent route into sessionKey as: agent:{agentId}:{rest}
    """
    agent_id = get_agent_for_conversation(conversation_id)
    if agent_id is None:
        error_msg = (
            f"âŒ ç¾¤æœªç»‘å®š AI Agent\n\n"
            f"å½“å‰ conversation_id: {conversation_id}\n\n"
            f"è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® OPENCLAW_GROUP_AGENT_MAPPING\n\n"
            f"é…ç½®ç¤ºä¾‹:\n"
            f'{{"cid_xxx":"agent-1","cid_yyy":"agent-2"}}\n\n'
            f"è¯¦è§éƒ¨ç½²æ–‡æ¡£æˆ–è”ç³»ç®¡ç†å‘˜"
        )
        yield {"error": error_msg}
        return

    # Stable session key for gateway-managed transcripts.
    rest_key = f"dingtalk:{conversation_id}:{sender_id}"
    session_key = f"agent:{agent_id}:{rest_key}"

    ws_url = OPENCLAW_GATEWAY_WS_URL or _derive_ws_url(OPENCLAW_HTTP_URL)
    if not ws_url:
        yield {"error": "OpenClaw WS æœªé…ç½®ï¼šè¯·è®¾ç½® OPENCLAW_GATEWAY_WS_URL æˆ– OPENCLAW_GATEWAY_URL"}
        return

    # Build chat.send attachments (images only)
    attachments = []
    if image_data_list:
        for idx, img in enumerate(image_data_list[:3], start=1):
            b64 = base64.b64encode(img).decode("utf-8")
            attachments.append({
                "type": "image",
                "mimeType": "image/jpeg",
                "fileName": f"image_{idx}.jpg",
                "content": b64,
            })

    # Compose user message. Keep it simple; gateway will stamp timestamp internally.
    # Note: callers typically already prefix speaker labels if needed.
    user_text = (message or "").strip()

    run_id = f"dingtalk-{uuid.uuid4().hex}"
    connect_req_id = f"connect-{uuid.uuid4().hex}"
    send_req_id = f"send-{uuid.uuid4().hex}"

    last_text = ""
    start_time = time.time()

    try:
        async with websockets.connect(
            ws_url,
            max_size=20 * 1024 * 1024,
            ping_interval=20,
            ping_timeout=20,
            close_timeout=5,
        ) as ws:
            await _ws_wait_for_challenge(ws, timeout_s=10.0)

            connect_frame = {
                "type": "req",
                "id": connect_req_id,
                "method": "connect",
                "params": {
                    "minProtocol": PROTOCOL_VERSION,
                    "maxProtocol": PROTOCOL_VERSION,
                    "client": {
                        "id": "gateway-client",
                        "version": "dingtalk-ai-bot",
                        "platform": "python",
                        "mode": "backend",
                    },
                    "role": "operator",
                    "scopes": [],
                    "auth": {"token": OPENCLAW_GATEWAY_TOKEN},
                },
            }
            await ws.send(json.dumps(connect_frame, ensure_ascii=False))
            connect_res = await _ws_wait_for_response(ws, connect_req_id, timeout_s=15.0)
            if not connect_res.get("ok"):
                err = (connect_res.get("error") or {}).get("message") or "unknown connect error"
                yield {"error": f"OpenClaw WS connect failed: {err}"}
                return

            send_frame = {
                "type": "req",
                "id": send_req_id,
                "method": "chat.send",
                "params": {
                    "sessionKey": session_key,
                    "message": user_text,
                    "attachments": attachments if attachments else None,
                    "timeoutMs": int(timeout_s * 1000),
                    "idempotencyKey": run_id,
                    "deliver": False,
                },
            }
            # Remove None fields for strict schema (additionalProperties=false)
            send_frame["params"] = {k: v for k, v in send_frame["params"].items() if v is not None}
            await ws.send(json.dumps(send_frame, ensure_ascii=False))

            send_res = await _ws_wait_for_response(ws, send_req_id, timeout_s=15.0)
            if not send_res.get("ok"):
                err = (send_res.get("error") or {}).get("message") or "unknown send error"
                yield {"error": f"OpenClaw WS chat.send failed: {err}"}
                return

            # Stream events until final/error/aborted for our run_id.
            deadline = time.time() + timeout_s
            while True:
                remaining = max(0.1, deadline - time.time())
                raw = await asyncio.wait_for(ws.recv(), timeout=remaining)
                obj = json.loads(raw)
                if obj.get("type") != "event" or obj.get("event") != "chat":
                    continue
                payload = obj.get("payload") or {}
                if payload.get("runId") != run_id:
                    continue

                state = payload.get("state")
                if state in {"delta", "final"}:
                    msg = payload.get("message") or {}
                    content = msg.get("content") or []
                    # Gateway sends full accumulated text in each delta; compute incremental diff.
                    text = ""
                    if isinstance(content, list) and content:
                        first = content[0] or {}
                        text = first.get("text") if isinstance(first, dict) else ""
                    if not isinstance(text, str):
                        text = ""

                    if text.startswith(last_text):
                        delta = text[len(last_text):]
                    else:
                        # Fallback: treat as full replacement (avoid dropping content).
                        delta = text
                        last_text = ""
                    last_text = text

                    if delta:
                        yield {"content": delta}

                    if state == "final":
                        break

                elif state == "error":
                    yield {"error": payload.get("errorMessage") or "OpenClaw WS run error"}
                    break
                elif state == "aborted":
                    yield {"error": "OpenClaw WS run aborted"}
                    break

            latency_ms = int((time.time() - start_time) * 1000)
            yield {"usage": {"latency_ms": latency_ms, "transport": "ws"}}

    except asyncio.TimeoutError:
        yield {"error": "OpenClaw WS è¯·æ±‚è¶…æ—¶"}
    except websockets.WebSocketException as e:
        yield {"error": f"OpenClaw WS Error: {e}"}
    except Exception as e:
        yield {"error": f"OpenClaw WS Error: {e}"}


def _parse_sse_delta(data: dict, state: dict) -> List[Dict]:
    """
    è§£æå•ä¸ª SSE data JSONï¼Œæå–å¢é‡å†…å®¹

    Args:
        data: è§£æåçš„ JSON å¯¹è±¡
        state: å¯å˜çŠ¶æ€å­—å…¸ (model, input_tokens, output_tokens)

    Returns:
        è¦ yield çš„ chunk åˆ—è¡¨
    """
    chunks = []

    if "model" in data:
        state["model"] = data["model"]

    if "usage" in data and data["usage"]:
        usage = data["usage"]
        state["input_tokens"] = usage.get("prompt_tokens", 0)
        state["output_tokens"] = usage.get("completion_tokens", 0)

    choices = data.get("choices", [])
    if not choices:
        return chunks

    delta = choices[0].get("delta", {})

    # æ€è€ƒå†…å®¹ (reasoning_content æˆ– thinking)
    thinking_delta = delta.get("reasoning_content") or delta.get("thinking") or ""
    if thinking_delta:
        state["thinking_len"] += len(thinking_delta)
        chunks.append({"thinking": thinking_delta})

    # æ­£å¼å›å¤å†…å®¹
    content_delta = delta.get("content") or ""
    if content_delta:
        state["content_len"] += len(content_delta)
        chunks.append({"content": content_delta})

    return chunks


async def call_openclaw_stream(
    messages: List[Dict],
    conversation_id: str,
    sender_id: str,
    sender_nick: str = "User",
    model: str = "openclaw",
    image_data_list: Optional[List[bytes]] = None,
) -> AsyncGenerator[Dict, None]:
    """
    è°ƒç”¨ OpenClaw Gateway HTTP API è¿›è¡Œæµå¼å¯¹è¯

    ä½¿ç”¨ OpenAI å…¼å®¹çš„ /v1/chat/completions ç«¯ç‚¹ï¼ŒSSE æµå¼è¿”å›ã€‚

    Args:
        messages: OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        conversation_id: ä¼šè¯ IDï¼ˆç”¨äºè·¯ç”±åˆ°ä¸åŒ agentï¼‰
        sender_id: å‘é€è€… ID
        sender_nick: å‘é€è€…æ˜µç§°
        model: æ¨¡å‹å»ºè®® (Gateway å¯è‡ªè¡Œå†³å®šæ˜¯å¦æ¥å—)

    Yields:
        {"content": "..."}   - æ­£å¼å›å¤å†…å®¹ (å¢é‡æ–‡æœ¬)
        {"thinking": "..."}  - æ€è€ƒå†…å®¹ (å¢é‡æ–‡æœ¬)
        {"error": "..."}     - é”™è¯¯ä¿¡æ¯
        {"usage": {...}}     - ä½¿ç”¨ç»Ÿè®¡
    """
    # WS transport is closer to official channel plugins and supports image attachments.
    if OPENCLAW_GATEWAY_TRANSPORT == "ws":
        # Prefer the last user content as message body (gateway manages transcript).
        last_user = ""
        for msg in reversed(messages or []):
            if msg.get("role") == "user":
                last_user = msg.get("content") or ""
                break
        if not isinstance(last_user, str):
            last_user = ""
        async for chunk in call_openclaw_ws_chat_stream(
            message=last_user,
            conversation_id=conversation_id,
            sender_id=sender_id,
            sender_nick=sender_nick,
            image_data_list=image_data_list,
        ):
            yield chunk
        return

    # æ ¹æ® conversation_id åŠ¨æ€é€‰æ‹© agent (HTTP/OpenAI-compatible path)
    agent_id = get_agent_for_conversation(conversation_id)

    # ä¸¥æ ¼è·¯ç”±æ¨¡å¼ï¼šæœªé…ç½®çš„ç¾¤è¿”å›é”™è¯¯æç¤º
    if agent_id is None:
        error_msg = (
            f"âŒ ç¾¤æœªç»‘å®š AI Agent\n\n"
            f"å½“å‰ conversation_id: {conversation_id}\n\n"
            f"è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½® OPENCLAW_GROUP_AGENT_MAPPING\n\n"
            f"é…ç½®ç¤ºä¾‹:\n"
            f'{{"cid_xxx":"agent-1","cid_yyy":"agent-2"}}\n\n'
            f"è¯¦è§éƒ¨ç½²æ–‡æ¡£æˆ–è”ç³»ç®¡ç†å‘˜"
        )
        print(f"ğŸš« {error_msg}")
        yield {"error": error_msg}
        return

    print(f"ğŸ“¡ æ­£åœ¨è¯·æ±‚ OpenClaw HTTP API (conversation_id={conversation_id}, agent={agent_id})...")

    start_time = time.time()

    # å…¼å®¹é€»è¾‘ï¼šå¦‚æœæ²¡æœ‰æŒ‡å®šç‰¹å®šæ¨¡å‹ï¼Œä½¿ç”¨ openclaw:{agent_id} æ ¼å¼
    # è¿™æœ‰åŠ©äºåœ¨ä¸ä¼ é€’ header çš„åœºæ™¯ä¸‹ä¹Ÿèƒ½è·¯ç”±ï¼ˆä½œä¸º fallbackï¼‰ï¼Œ
    # ä½†æˆ‘ä»¬ä¸‹é¢ä¼šæ˜¾å¼ä¼ é€’ x-openclaw-agent-id headerã€‚
    if model and model not in {"openclaw", "default"}:
        request_model = model
    else:
        request_model = f"openclaw:{agent_id}"

    request_body = {
        "model": request_model,
        "messages": messages,
        "stream": True,
        # ç»™ Gateway ä¸€ä¸ªç¨³å®šçš„ userï¼Œæœ‰åŠ©äºä¼šè¯ç²˜æ€§ï¼ˆåŒä¸€ç¾¤/åŒä¸€ç”¨æˆ·ï¼‰ã€‚
        "user": f"dingtalk:{conversation_id}:{sender_id}",
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENCLAW_GATEWAY_TOKEN}",
        "x-openclaw-agent-id": agent_id,  # æ˜¾å¼ Header è·¯ç”±
    }

    # è§£æçŠ¶æ€
    state = {
        "model": request_model,
        "input_tokens": 0,
        "output_tokens": 0,
        "content_len": 0,
        "thinking_len": 0,
    }

    try:
        # ä¸èµ°ä»£ç† (OpenClaw æ˜¯å†…ç½‘æœåŠ¡)
        connector = aiohttp.TCPConnector(force_close=True, enable_cleanup_closed=True)
        timeout = aiohttp.ClientTimeout(total=300, sock_read=300, sock_connect=30)
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            async with session.post(
                OPENCLAW_HTTP_URL,
                json=request_body,
                headers=headers,
                proxy=None,
            ) as resp:
                if resp.status != 200:
                    error_text = await resp.text()
                    print(f"âŒ OpenClaw HTTP é”™è¯¯ ({resp.status}): {error_text[:500]}")
                    yield {"error": f"OpenClaw HTTP Error ({resp.status}): {error_text[:200]}"}
                    return

                # é€è¡Œè¯»å– SSE æµ (readline ä¿è¯è¡Œå®Œæ•´æ€§)
                # è¯´æ˜ï¼šæŸäº›ç½‘ç»œ/ä»£ç†/ä¸­é—´ä»¶å¯èƒ½å¯¼è‡´è¿æ¥æå‰æ–­å¼€ï¼Œaiohttp ä¼šæŠ› TransferEncodingErrorã€‚
                try:
                    while True:
                        line_bytes = await resp.content.readline()
                        if not line_bytes:
                            break

                        line = line_bytes.decode("utf-8", errors="replace").strip()

                        if not line or line.startswith(":"):
                            continue

                        if not line.startswith("data: "):
                            continue

                        data_str = line[6:]
                        if data_str == "[DONE]":
                            break

                        try:
                            data = json.loads(data_str)
                        except json.JSONDecodeError:
                            continue

                        for chunk in _parse_sse_delta(data, state):
                            yield chunk
                except aiohttp.ClientPayloadError as e:
                    # å¸¸è§æŠ¥é”™ï¼šResponse payload is not completed / TransferEncodingError
                    print(f"âš ï¸ OpenClaw HTTP SSE payload æœªå®Œæ•´ï¼ˆå¯èƒ½è¿æ¥è¢«ä¸­æ–­ï¼‰ï¼š{e}")
                    # å°½é‡æŠŠå·²ç”Ÿæˆçš„å†…å®¹äº¤ç»™ä¸Šæ¸¸ï¼›ä¸è¦åœ¨è¿™é‡Œç›´æ¥å½“ä½œå¤±è´¥ç»ˆæ­¢ã€‚
                    yield {
                        "error": "OpenClaw æµå¼è¿æ¥ä¸­æ–­ï¼ˆpayload æœªå®Œæ•´ï¼‰ã€‚å¦‚é¢‘ç¹å‡ºç°ï¼Œè¯·æ£€æŸ¥ WAF/åä»£/HTTP2 è®¾ç½®ã€‚"
                    }
                    return

        # è¾“å‡ºç»Ÿè®¡
        latency_ms = int((time.time() - start_time) * 1000)
        print(f"âœ… OpenClaw HTTP æµå¼å“åº”ç»“æŸ | å»¶è¿Ÿ: {latency_ms}ms, å†…å®¹é•¿åº¦: {state['content_len']}")

        yield {
            "usage": {
                "model": state["model"],
                "input_tokens": state["input_tokens"],
                "output_tokens": state["output_tokens"],
                "latency_ms": latency_ms
            }
        }

    except aiohttp.ClientError as e:
        print(f"âŒ OpenClaw HTTP è¿æ¥é”™è¯¯: {e}")
        yield {"error": f"OpenClaw HTTP Error: {e}"}

    except asyncio.TimeoutError:
        print("âš ï¸ OpenClaw HTTP è¯·æ±‚è¶…æ—¶ (180s)")
        yield {"error": "OpenClaw HTTP è¯·æ±‚è¶…æ—¶"}

    except Exception as e:
        print(f"âŒ OpenClaw API é”™è¯¯: {e}")
        yield {"error": f"OpenClaw API Error: {e}"}


async def close_openclaw_client():
    """å…³é—­ OpenClaw å®¢æˆ·ç«¯è¿æ¥ (å…¼å®¹æ—§æ¥å£ï¼ŒHTTP æ¨¡å¼æ— éœ€æ¸…ç†)"""
    pass
